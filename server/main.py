import os
import io
import json
import base64
import random
import uuid
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, Optional, List
import asyncio

import httpx
from dotenv import load_dotenv
from fastapi import FastAPI, UploadFile, File, Form, Query
from fastapi.responses import JSONResponse, FileResponse
from fastapi.staticfiles import StaticFiles
from fastapi.middleware.cors import CORSMiddleware
from fastapi import BackgroundTasks

# Google Drive OAuth (optional)
from google.oauth2.credentials import Credentials
from googleapiclient.discovery import build
from googleapiclient.http import MediaIoBaseUpload


# =========================
# ENV
# =========================
load_dotenv()

API_KEY = (os.getenv("RUNNINGHUB_API_KEY") or "").strip()
WORKFLOW_ID = (os.getenv("RUNNINGHUB_WORKFLOW_ID") or "").strip()
BASE = (os.getenv("RUNNINGHUB_BASE") or "https://www.runninghub.ai").strip()
PORT = int(os.getenv("PORT") or "8080")

RH_CREATE = f"{BASE}/task/openapi/create"
RH_OUTPUTS = f"{BASE}/task/openapi/outputs"

# Google Drive OAuth controls
GDRIVE_ENABLED = (os.getenv("GDRIVE_ENABLED") or "0").strip() == "1"
GDRIVE_ROOT_FOLDER_ID = (os.getenv("GDRIVE_ROOT_FOLDER_ID") or "").strip()
SCOPES = ["https://www.googleapis.com/auth/drive.file"]


# =========================
# PATHS
# =========================
SERVER_DIR = Path(__file__).resolve().parent
PROJECT_ROOT = SERVER_DIR.parent
WEB_DIR = PROJECT_ROOT / "web"

ARCHIVE_DIR = SERVER_DIR / "archive"
ARCHIVE_DIR.mkdir(parents=True, exist_ok=True)

TOKEN_PATH = SERVER_DIR / "token.json"  # generated by your one-time OAuth login script


# =========================
# APP
# =========================
app = FastAPI()
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # demo-friendly; tighten for production
    allow_methods=["*"],
    allow_headers=["*"],
)


# =========================
# HELPERS
# =========================
def require_env():
    if not API_KEY or not WORKFLOW_ID:
        return JSONResponse(
            status_code=500,
            content={"error": "Missing RUNNINGHUB_API_KEY or RUNNINGHUB_WORKFLOW_ID in server/.env"},
        )
    return None


async def rh_post_json(url: str, payload: Dict[str, Any]) -> Dict[str, Any]:
    async with httpx.AsyncClient(timeout=180) as client:
        r = await client.post(url, json=payload)
        try:
            j = r.json()
        except Exception:
            j = {"raw": r.text}
        if r.status_code >= 400:
            raise RuntimeError(f"RunningHub HTTP {r.status_code}: {j}")
        return j


def extract_task_id(resp: Dict[str, Any]) -> Optional[str]:
    data = resp.get("data")
    if isinstance(data, dict):
        return data.get("taskId") or data.get("task_id") or data.get("id")
    if isinstance(data, str):
        return data
    return resp.get("taskId") or resp.get("task_id")


def find_first_http_url(obj: Any) -> Optional[str]:
    found: List[str] = []

    def walk(x: Any):
        if isinstance(x, list):
            for i in x:
                walk(i)
        elif isinstance(x, dict):
            for k in ["fileUrl", "url", "file", "path"]:
                v = x.get(k)
                if isinstance(v, str) and v.startswith("http"):
                    found.append(v)
            for v in x.values():
                walk(v)

    walk(obj)
    return found[0] if found else None


def make_archive_id() -> str:
    # one folder per play
    ts = datetime.now().strftime("%Y-%m-%d_%H%M%S")
    uid = uuid.uuid4().hex[:8]
    return f"{ts}_{uid}"


def get_play_dir(archive_id: str) -> Path:
    d = ARCHIVE_DIR / archive_id
    d.mkdir(parents=True, exist_ok=True)
    return d


# =========================
# Google Drive (OAuth)
# =========================
def get_drive():
    if not TOKEN_PATH.exists():
        raise RuntimeError("token.json not found in server/. Run your OAuth login script to generate it.")
    creds = Credentials.from_authorized_user_file(str(TOKEN_PATH), SCOPES)
    return build("drive", "v3", credentials=creds)


def drive_create_folder(drive, name: str, parent_id: str = "") -> str:
    body = {"name": name, "mimeType": "application/vnd.google-apps.folder"}
    if parent_id:
        body["parents"] = [parent_id]
    folder = drive.files().create(body=body, fields="id").execute()
    return folder["id"]


def drive_upload_bytes(drive, name: str, data: bytes, mime: str, parent_id: str) -> Dict[str, Any]:
    media = MediaIoBaseUpload(io.BytesIO(data), mimetype=mime, resumable=False)
    file = drive.files().create(
        body={"name": name, "parents": [parent_id]},
        media_body=media,
        fields="id, webViewLink"
    ).execute()
    return file


def drive_upload_text(drive, name: str, text: str, parent_id: str) -> Dict[str, Any]:
    data = text.encode("utf-8")
    return drive_upload_bytes(drive, name, data, "application/json", parent_id)



async def finalize_job(task_id: str, archive_id: str):
    play_dir = get_play_dir(archive_id)
    meta_path = play_dir / "meta.json"
    meta = {}
    if meta_path.exists():
        meta = json.loads(meta_path.read_text(encoding="utf-8"))

    output_path = play_dir / "output.png"
    if output_path.exists():
        return  # already finalized

    # Poll outputs up to ~10 minutes (300 * 2s)
    image_url = None
    for _ in range(300):
        try:
            out = await rh_post_json(RH_OUTPUTS, {"apiKey": API_KEY, "taskId": task_id})
            data = out.get("data", out)
            image_url = find_first_http_url(data)
            if image_url:
                break
        except Exception:
            pass
        await asyncio.sleep(2)

    if not image_url:
        # optional: record failure
        meta["finalizeError"] = "Timeout waiting for RunningHub output"
        meta_path.write_text(json.dumps(meta, indent=2, ensure_ascii=False), encoding="utf-8")
        return

    # download bytes
    async with httpx.AsyncClient(timeout=180) as client:
        r = await client.get(image_url)
        r.raise_for_status()
        img_bytes = r.content

    # save locally
    output_path.write_bytes(img_bytes)

    # upload to Drive
    drive_folder_id = meta.get("driveFolderId")
    if GDRIVE_ENABLED and drive_folder_id:
        drive = get_drive()
        drive_upload_bytes(drive, "output.png", img_bytes, "image/png", drive_folder_id)

    # update meta
    meta["outputUrl"] = image_url
    meta["finalizedAt"] = datetime.now().isoformat()
    meta_path.write_text(json.dumps(meta, indent=2, ensure_ascii=False), encoding="utf-8")

    # upload meta.json to Drive
    if GDRIVE_ENABLED and drive_folder_id:
        drive = get_drive()
        drive_upload_text(drive, "meta.json", json.dumps(meta, indent=2, ensure_ascii=False), drive_folder_id)


# =========================
# ROUTES
# =========================
@app.get("/health")
def health():
    return {"ok": True}


@app.post("/api/run")
async def api_run(
    photo: UploadFile = File(...),
    templateId: str = Form("fai_chun_01"),
    seed: Optional[int] = Form(None),
):
    missing = require_env()
    if missing:
        return missing

    TEMPLATE_TO_INT = {
        "fai_chun_01": 1,
        "fai_chun_02": 2,
        "fai_chun_03": 3,
        "fai_chun_04": 4,
    }

    try:
        img_bytes = await photo.read()
        img_b64 = base64.b64encode(img_bytes).decode("utf-8")

        # Archive per play
        archive_id = make_archive_id()
        play_dir = get_play_dir(archive_id)

        (play_dir / "input.jpg").write_bytes(img_bytes)

        # Google Drive: create folder per play + upload input
        drive_folder_id = None
        if GDRIVE_ENABLED:
            drive = get_drive()
            drive_folder_id = drive_create_folder(drive, archive_id, GDRIVE_ROOT_FOLDER_ID)
            drive_upload_bytes(drive, "input.jpg", img_bytes, "image/jpeg", drive_folder_id)

        if seed is None:
            seed = random.randint(100_000_000, 999_999_999)

        # RunningHub overrides
        switch_value = TEMPLATE_TO_INT.get(templateId, 1)
        node_info_list = [
            {"nodeId": "627", "fieldName": "data", "fieldValue": img_b64},
            {"nodeId": "582", "fieldName": "value", "fieldValue": str(int(switch_value))},
            {"nodeId": "471", "fieldName": "noise_seed", "fieldValue": str(int(seed))},
        ]

        run_resp = await rh_post_json(
            RH_CREATE,
            {
                "apiKey": API_KEY,
                "workflowId": WORKFLOW_ID,
                "nodeInfoList": node_info_list,
            },
        )

        task_id = extract_task_id(run_resp)
        if not task_id:
            raise RuntimeError(f"Missing taskId from run response: {run_resp}")

        # meta.json (local)
        meta = {
            "archiveId": archive_id,
            "taskId": task_id,
            "templateId": templateId,
            "seed": seed,
            "createdAt": datetime.now().isoformat(),
            "driveFolderId": drive_folder_id,  # None if disabled
        }
        (play_dir / "meta.json").write_text(json.dumps(meta, indent=2, ensure_ascii=False), encoding="utf-8")

        # meta.json (Drive)
        if GDRIVE_ENABLED and drive_folder_id:
            drive = get_drive()
            drive_upload_text(drive, "meta.json", json.dumps(meta, indent=2, ensure_ascii=False), drive_folder_id)

        return {"taskId": task_id, "archiveId": archive_id}
        
        # âœ… Auto finalize in background (archives output even if user closes page)
        background_tasks.add_task(finalize_job, task_id, archive_id)


    except Exception as e:
        return JSONResponse(status_code=500, content={"error": str(e)})


@app.get("/api/result")
async def api_result(taskId: str = Query(...)):
    """Return 200 always: ready=false until outputs exist (no 404 spam)."""
    missing = require_env()
    if missing:
        return missing

    try:
        out = await rh_post_json(RH_OUTPUTS, {"apiKey": API_KEY, "taskId": taskId})
        data = out.get("data", out)
        image_url = find_first_http_url(data)

        if not image_url:
            return {"ready": False, "imageUrl": None}

        return {"ready": True, "imageUrl": image_url}

    except Exception as e:
        return JSONResponse(status_code=500, content={"error": str(e)})


@app.post("/api/finalize")
async def api_finalize(taskId: str = Form(...), archiveId: str = Form(...)):
    """
    Auto-archive output (local + Google Drive) as soon as result is ready.
    This is called by the frontend right after it receives ready=true.
    Safe to call multiple times.
    """
    missing = require_env()
    if missing:
        return missing

    try:
        play_dir = get_play_dir(archiveId)
        meta_path = play_dir / "meta.json"
        meta: Dict[str, Any] = {}
        if meta_path.exists():
            meta = json.loads(meta_path.read_text(encoding="utf-8"))

        output_path = play_dir / "output.png"
        if output_path.exists():
            return {"ok": True, "alreadyFinalized": True}

        rs = await api_result(taskId)
        if isinstance(rs, JSONResponse):
            return rs
        if not rs.get("ready"):
            return JSONResponse(status_code=400, content={"error": "Result not ready yet"})

        image_url = rs["imageUrl"]

        # download output bytes
        async with httpx.AsyncClient(timeout=180) as client:
            r = await client.get(image_url)
            r.raise_for_status()
            img_bytes = r.content

        # save locally
        output_path.write_bytes(img_bytes)

        # upload output + meta to Drive (same folder as input)
        drive_folder_id = meta.get("driveFolderId")
        if GDRIVE_ENABLED and drive_folder_id:
            drive = get_drive()
            drive_upload_bytes(drive, "output.png", img_bytes, "image/png", drive_folder_id)

        # update meta and save locally
        meta["outputUrl"] = image_url
        meta["finalizedAt"] = datetime.now().isoformat()
        meta_path.write_text(json.dumps(meta, indent=2, ensure_ascii=False), encoding="utf-8")

        # upload updated meta.json to Drive
        if GDRIVE_ENABLED and drive_folder_id:
            drive = get_drive()
            drive_upload_text(drive, "meta.json", json.dumps(meta, indent=2, ensure_ascii=False), drive_folder_id)

        return {"ok": True}

    except Exception as e:
        return JSONResponse(status_code=500, content={"error": str(e)})


@app.get("/api/download")
async def api_download(taskId: str, archiveId: str):
    """
    If output already exists locally (finalized), return it directly.
    Otherwise fetch from RunningHub, save locally + Drive, and return.
    """
    missing = require_env()
    if missing:
        return missing

    try:
        play_dir = get_play_dir(archiveId)
        meta_path = play_dir / "meta.json"
        meta = {}
        if meta_path.exists():
            meta = json.loads(meta_path.read_text(encoding="utf-8"))

        # If already finalized (output saved), return local file directly
        output_path = play_dir / "output.png"
        if output_path.exists():
            meta["downloadedAt"] = datetime.now().isoformat()
            meta_path.write_text(json.dumps(meta, indent=2, ensure_ascii=False), encoding="utf-8")
            return FileResponse(
                output_path,
                media_type="image/png",
                filename=f"AI_FaiChun_{archiveId}.png",
            )

        # Not finalized yet -> finalize now by pulling output
        rs = await api_result(taskId)
        if isinstance(rs, JSONResponse):
            return rs
        if not rs.get("ready"):
            return JSONResponse(status_code=400, content={"error": "Result not ready yet"})

        image_url = rs["imageUrl"]

        async with httpx.AsyncClient(timeout=180) as client:
            r = await client.get(image_url)
            r.raise_for_status()
            img_bytes = r.content

        output_path.write_bytes(img_bytes)

        drive_folder_id = meta.get("driveFolderId")
        if GDRIVE_ENABLED and drive_folder_id:
            drive = get_drive()
            drive_upload_bytes(drive, "output.png", img_bytes, "image/png", drive_folder_id)

        meta["outputUrl"] = image_url
        meta["finalizedAt"] = meta.get("finalizedAt") or datetime.now().isoformat()
        meta["downloadedAt"] = datetime.now().isoformat()
        meta_path.write_text(json.dumps(meta, indent=2, ensure_ascii=False), encoding="utf-8")

        if GDRIVE_ENABLED and drive_folder_id:
            drive = get_drive()
            drive_upload_text(drive, "meta.json", json.dumps(meta, indent=2, ensure_ascii=False), drive_folder_id)

        return FileResponse(
            output_path,
            media_type="image/png",
            filename=f"AI_FaiChun_{archiveId}.png",
        )

    except Exception as e:
        return JSONResponse(status_code=500, content={"error": str(e)})


# =========================
# SERVE WEBSITE (mount last so /api routes win)
# =========================
app.mount("/", StaticFiles(directory=WEB_DIR, html=True), name="web")


# =========================
# MAIN
# =========================
if __name__ == "__main__":
    import uvicorn
    uvicorn.run("main:app", host="localhost", port=PORT, reload=True)
